{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Leave-One-Out\n",
    "\n",
    "This notebook will explain in detail how to reproduce the experiments conducted for the XAI method Leave-One-Out applied to Key-Point Analysis."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilities\n",
    "\n",
    "First, we need to import libraries used in this notebook, define helper functions and variables."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "from itertools import chain, combinations\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import sbert_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def save_with_pickle(path, data):\n",
    "    with open(path, \"wb\") as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_from_pickle(path):\n",
    "    with open(path, \"rb\") as handle:\n",
    "        data = pickle.load(handle)\n",
    "    return data\n",
    "\n",
    "def load_closed_class_words(path):\n",
    "    data = []\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            data.extend(line.split())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def compute_score(arg, kp, model):\n",
    "    \"\"\"This function gives an arg-kp-pair a score by the\n",
    "    means of cosine similarity. Expects a model to be passed\"\"\"\n",
    "    arg = model.encode(arg, show_progress_bar=False),\n",
    "    kp = model.encode(kp, show_progress_bar=False)\n",
    "    return float(util.pytorch_cos_sim(arg, kp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "word_tokenizer = word_tokenize\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "closed_class_words = load_closed_class_words(\"./Data/LOO_Data/closed_class_words.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "\n",
    "Next, we need to train the model. Training can be conducted by running `sbert_training.py` or downloaded [here](https://drive.google.com/drive/folders/1qgGdoNMUcyQivTtu5udzGcQB8SFgxm-M?usp=sharing)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-28 13:40:35 - Load pretrained SentenceTransformer: ./Data/LOO_Data/Model\n",
      "2022-02-28 13:40:36 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./Data/LOO_Data/Model\"\n",
    "model = sbert_training.train_model(dataset_path='./Data/LOO_Data/SiameseData', eval_data_path='./Data/LOO_Data/KPMData',\n",
    "                                   subset_name='dev', output_path=model_path, model_name='roberta-base',\n",
    "                                   model_suffix='contrastive-10-epochs', data_file_suffix='contrastive',\n",
    "                                   num_epochs=10, max_seq_length=70, add_special_token=True, train_batch_size=32,\n",
    "                                   loss='ContrastiveLoss') if not os.listdir(model_path) else SentenceTransformer(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data\n",
    "\n",
    "Once we have model at our disposal we need to prepare the data. To do this, we iterate over all possible argument-key-point pairs given in the dataset. Pairs which belong together are concatened into a data row. We pre-compute both the model `predictions` and the gold-standard, though later on we will only work with the model predictions for obvious reasons. The computations for this are very expensive and take almost a full day hence the pre-computation. In order to not having to compute over and over again we include the computed predictions and the gold standard.\n",
    "\n",
    "The `gold_labels_and_predictions.pkl` is a nested dictionary. It can be accesed as:\n",
    "`data = dict[dev|train][predictions|gold_standard]`\n",
    "Run the cell below the loading cell to see an example."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelbraasch/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/torch/cuda/__init__.py:143: UserWarning: \n",
      "NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36m<cell line: 35>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 36\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mload_from_pickle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mload_from_pickle\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_pickle\u001B[39m(path):\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[1;32m      7\u001B[0m         data \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(handle)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './Data/LOO_Data/gold_labels_and_predictions_scores.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36m<cell line: 35>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m     data \u001B[38;5;241m=\u001B[39m load_from_pickle(data_path)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m---> 38\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_gold_labels_and_prediction_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36mcreate_gold_labels_and_prediction_scores\u001B[0;34m(model, path)\u001B[0m\n\u001B[1;32m     22\u001B[0m mappings \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m topic, arg_kps_mapping \u001B[38;5;129;01min\u001B[39;00m arg_to_kps\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 24\u001B[0m     arg_kps_mapping[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43marg_kps_mapping\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompute_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43margument\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkey_point\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m     arg_kps_mapping[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m topic\n\u001B[1;32m     26\u001B[0m     arg_kps_mapping \u001B[38;5;241m=\u001B[39m arg_kps_mapping[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margument\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkey_point\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/pandas/core/frame.py:8833\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[1;32m   8822\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m   8824\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m   8825\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   8826\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   8831\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m   8832\u001B[0m )\n\u001B[0;32m-> 8833\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/pandas/core/apply.py:727\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    725\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[0;32m--> 727\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/pandas/core/apply.py:851\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 851\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[1;32m    854\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/pandas/core/apply.py:867\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    864\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[1;32m    866\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    868\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[1;32m    869\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[1;32m    870\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[1;32m    871\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36mcreate_gold_labels_and_prediction_scores.<locals>.<lambda>\u001B[0;34m(row)\u001B[0m\n\u001B[1;32m     22\u001B[0m mappings \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m topic, arg_kps_mapping \u001B[38;5;129;01min\u001B[39;00m arg_to_kps\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 24\u001B[0m     arg_kps_mapping[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m arg_kps_mapping\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m row: \u001B[43mcompute_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43margument\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkey_point\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     25\u001B[0m     arg_kps_mapping[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m topic\n\u001B[1;32m     26\u001B[0m     arg_kps_mapping \u001B[38;5;241m=\u001B[39m arg_kps_mapping[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margument\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkey_point\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\n",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36mcompute_score\u001B[0;34m(arg, kp, model)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_score\u001B[39m(arg, kp, model):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124;03m\"\"\"This function gives an arg-kp-pair a score by the\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m    means of cosine similarity. Expects a model to be passed\"\"\"\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m     arg \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[1;32m      5\u001B[0m     kp \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(kp, show_progress_bar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(util\u001B[38;5;241m.\u001B[39mpytorch_cos_sim(arg, kp))\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:164\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[1;32m    161\u001B[0m features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 164\u001B[0m     out_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    167\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 141\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:66\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m features:\n\u001B[1;32m     64\u001B[0m     trans_features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 66\u001B[0m output_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauto_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrans_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m output_tokens \u001B[38;5;241m=\u001B[39m output_states[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     69\u001B[0m features\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m: output_tokens, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]})\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:823\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    819\u001B[0m         token_type_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(input_shape, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m    821\u001B[0m \u001B[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001B[39;00m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001B[39;00m\n\u001B[0;32m--> 823\u001B[0m extended_attention_mask: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_extended_attention_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[38;5;66;03m# If a 2D or 3D attention mask is provided for the cross-attention\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;66;03m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001B[39;00m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_decoder \u001B[38;5;129;01mand\u001B[39;00m encoder_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/XAI_test/kpa_env/lib/python3.8/site-packages/transformers/modeling_utils.py:306\u001B[0m, in \u001B[0;36mModuleUtilsMixin.get_extended_attention_mask\u001B[0;34m(self, attention_mask, input_shape, device)\u001B[0m\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    298\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrong shape for input_ids (shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) or attention_mask (shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattention_mask\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    299\u001B[0m     )\n\u001B[1;32m    301\u001B[0m \u001B[38;5;66;03m# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\u001B[39;00m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;66;03m# masked positions, this operation will create a tensor which is 0.0 for\u001B[39;00m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;66;03m# positions we want to attend and -10000.0 for masked positions.\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;66;03m# Since we are adding it to the raw scores before the softmax, this is\u001B[39;00m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;66;03m# effectively the same as removing these entirely.\u001B[39;00m\n\u001B[0;32m--> 306\u001B[0m extended_attention_mask \u001B[38;5;241m=\u001B[39m \u001B[43mextended_attention_mask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# fp16 compatibility\u001B[39;00m\n\u001B[1;32m    307\u001B[0m extended_attention_mask \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m extended_attention_mask) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m10000.0\u001B[39m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m extended_attention_mask\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\", line 861, in trace_dispatch\n",
      "    result = plugin_manager.cmd_step_over(main_debugger, frame, event, self._args, stop_info, stop)\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 144, in cmd_step_over\n",
      "    if _is_inside_jupyter_cell(frame, pydb):\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 209, in _is_inside_jupyter_cell\n",
      "    if is_cell_filename(filename):\n",
      "  File \"/home/marcelbraasch/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/213.5744.248/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\", line 220, in is_cell_filename\n",
      "    ipython_shell = get_ipython()\n",
      "NameError: name 'get_ipython' is not defined\n"
     ]
    }
   ],
   "source": [
    "def create_gold_labels_and_prediction_scores(model, path):\n",
    "    data = defaultdict(dict)\n",
    "    for subset in [\"dev\", \"train\"]:\n",
    "        # Load files\n",
    "        arguments_file = f\"./Data/LOO_Data/kpm_data/arguments_{subset}.csv\"\n",
    "        key_points_file = f\"./Data/LOO_Data/kpm_data/key_points_{subset}.csv\"\n",
    "        labels_file = f\"./Data/LOO_Data/kpm_data/labels_{subset}.csv\"\n",
    "        arguments_df = pd.read_csv(arguments_file)\n",
    "        key_points_df = pd.read_csv(key_points_file)\n",
    "        labels_df = pd.read_csv(labels_file)\n",
    "        # Get gold standard\n",
    "        positive_labels_df = labels_df.loc[labels_df[\"label\"] == 1]\n",
    "        gold_standard = pd.merge(positive_labels_df, key_points_df, how=\"inner\", on=\"key_point_id\")\n",
    "        gold_standard = pd.merge(gold_standard, arguments_df, how=\"inner\", on=[\"arg_id\",\"topic\", \"stance\"])\n",
    "        gold_standard = gold_standard.rename(columns={\"label\": \"score\"})\n",
    "        data[subset][\"gold_standard\"] = gold_standard\n",
    "        # Within a topic map every key-point to every argument\n",
    "        arg_to_kps = {topic: pd.merge(arguments_df.loc[arguments_df[\"topic\"] == topic][[\"argument\"]].drop_duplicates(),\n",
    "                              key_points_df.loc[key_points_df[\"topic\"] == topic][[\"key_point\"]].drop_duplicates(),\n",
    "                              how=\"cross\") for topic in arguments_df[\"topic\"].unique()}\n",
    "        # Create predictions\n",
    "        mappings = []\n",
    "        for topic, arg_kps_mapping in arg_to_kps.items():\n",
    "            arg_kps_mapping['score'] = arg_kps_mapping.apply(lambda row: compute_score(row[\"argument\"], row[\"key_point\"], model), axis=1)\n",
    "            arg_kps_mapping['topic'] = topic\n",
    "            arg_kps_mapping = arg_kps_mapping[[\"topic\", \"argument\", \"key_point\", \"score\"]]\n",
    "            mappings.append(arg_kps_mapping)\n",
    "        predictions = pd.concat(mappings, axis=0)\n",
    "        data[subset][\"predictions\"] = predictions\n",
    "    save_with_pickle(path, data)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now we load or compute the data\n",
    "data_path = \"./Data/LOO_Data/gold_labels_and_prediction_scores.pkl\"\n",
    "try:\n",
    "    data = load_from_pickle(data_path)\n",
    "except:\n",
    "    data = create_gold_labels_and_prediction_scores(model, data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         topic  \\\n",
      "0  We should abandon the use of school uniform   \n",
      "1  We should abandon the use of school uniform   \n",
      "\n",
      "                                            argument  \\\n",
      "0  having a school uniform can reduce bullying as...   \n",
      "1  having a school uniform can reduce bullying as...   \n",
      "\n",
      "                                           key_point     score  \n",
      "0  Children can still express themselves using ot...  0.556963  \n",
      "1                    School uniform reduces bullying  0.686188  \n"
     ]
    }
   ],
   "source": [
    "# Preview of what the model's predictions datastructure looks like\n",
    "predictions = data[\"dev\"][\"predictions\"]\n",
    "print(predictions.head(2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating masked arguments\n",
    "\n",
    "Now that we have our model and the data prepared we can move one to masking, or more specifically, dropping the random n-gram combinations (as described in the technical report). The idea is simple. For each sentence, we tokenize and create the powerset of these. Every subset which is smaller than `n+1` will be created and stored in map. Later we will iterate over all arguments and create the scoring with the dropped combinatations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "def _create_dropped_combinations(argument, drop_size=4):\n",
    "    tokens = word_tokenizer(argument)\n",
    "    samples = []\n",
    "    lexical_mask = [1 if x not in closed_class_words else 0 for x in tokens]\n",
    "    lexical_indices = [i for i, x in enumerate(lexical_mask) if x]\n",
    "    lexical_indices_combinations = powerset(lexical_indices)\n",
    "    lexical_indices_combinations = [x for x in lexical_indices_combinations\n",
    "                                    if len(x)<=drop_size][1:]\n",
    "    for combination in lexical_indices_combinations:\n",
    "        combination = list(combination)\n",
    "        combination.sort(reverse=True)\n",
    "        new_arg = copy.deepcopy(tokens)\n",
    "        dropped_words = [new_arg.pop(index) for index in combination]\n",
    "        sample = {\"dropped\": dropped_words,\n",
    "                  \"new_arg\": \" \".join(new_arg),\n",
    "                  \"amount_dropped\": len(combination),\n",
    "                  \"indices\": combination}\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "def create_dropped_combinations(arguments, data_path):\n",
    "    mapping = {argument:_create_dropped_combinations(argument)\n",
    "               for argument in tqdm_notebook(arguments)}\n",
    "    save_with_pickle(data_path, mapping)\n",
    "    return mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Get unique topics, arguments, key_points.\n",
    "# This will be needed in a few function later.\n",
    "arguments = predictions[\"argument\"].unique()\n",
    "topics = predictions[\"topic\"].unique()\n",
    "key_points = predictions[\"key_point\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Now we load or compute the mapping from the argument to all its dropped combinations\n",
    "data_path = \"./Data/LOO_Data/arg_to_dropped_mapping.pkl\"\n",
    "try:\n",
    "    arg_to_dropped = load_from_pickle(data_path)\n",
    "except:\n",
    "    arg_to_dropped = create_dropped_combinations(arguments, data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Now we can move on to the actual computation of Leave-N-Out. We pre-computed for each argument the matching key-point (according to the model) and built a mapping from each argument to all its random dropped combinations. It is important to note that we not only compute the importance of arguments and its argmax key-point, but scores of the argument with _all_ key-points. This allows to compare across key-points to answer the question which words are present in the argmax key-point that are not in the others."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class Importance:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "        self.scores = []\n",
    "\n",
    "    def update(self, score):\n",
    "        self.counter += 1\n",
    "        self.scores.append(score)\n",
    "\n",
    "    def get(self):\n",
    "        return sum(self.scores) / self.counter\n",
    "\n",
    "def _compute_word_importance(argument, key_point, arg_to_dropped, model):\n",
    "    reference = compute_score(argument, key_point, model)\n",
    "    dropped = arg_to_dropped[argument][:750]\n",
    "    word_to_importance = defaultdict(Importance)\n",
    "    for example in tqdm_notebook(dropped):\n",
    "        dropped_words, new_argument, amount_dropped, indices = example.values()\n",
    "        new_score = compute_score(new_argument, key_point, model)\n",
    "        difference = reference - new_score\n",
    "        for word in dropped_words:\n",
    "            word_to_importance[word].update(difference)\n",
    "    return {word: importance.get() for word, importance in word_to_importance.items()}\n",
    "\n",
    "def compute_word_importances_of_all_arg_kps(predictions, arg_to_dropped):\n",
    "        args_kps = predictions\n",
    "        arg_to_dropped = create_dropped_combinations(args_kps[\"argument\"].unique())\n",
    "        args_kps[\"important_words\"] = args_kps.apply(lambda row: _compute_word_importance(row[\"argument\"], row[\"key_point\"], arg_to_dropped, model), axis=1)\n",
    "        save_with_pickle(\"word_importance.pkl\", args_kps)\n",
    "        return args_kps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Now we load or compute the mapping from the argument to all its dropped combinations\n",
    "data_path = \"./Data/LOO_Data/word_importance.pkl\"\n",
    "try:\n",
    "    word_importances = load_from_pickle(data_path)\n",
    "except:\n",
    "    word_importances = compute_word_importances_of_all_arg_kps(model, data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Leave-N-Out: Visualization\n",
    "\n",
    "Word importances for each argument-key-point pair are computed, but not structured very nicely and just in a raw dictionary. In the cell below you can see a preview. In this section we will do a little bit of data wrangling such that we can nicely view the data in a dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def create_leave_one_out_for_args():\n",
    "    loo = []\n",
    "    for topic in topics:\n",
    "        # Get all unique key points for a specific topic\n",
    "        key_points = predictions.loc[predictions['topic'] == topic][\"key_point\"].unique()\n",
    "        for argument in tqdm_notebook(arguments):\n",
    "            # Get the top n key points corresponding to current argument\n",
    "            top_n = word_importances.loc[word_importances[\"argument\"]==argument] \\\n",
    "                                    .sort_values(by=[\"score\"], ascending=False).head(5)\n",
    "            df = pd.DataFrame()\n",
    "            for i, row in enumerate(top_n.iterrows()):\n",
    "                topic, argument, key_point, score, importances = row[1]\n",
    "                # Extract word importance scores\n",
    "                importances = pd.DataFrame.from_dict({x:[y] for x,y in importances.items()}) \\\n",
    "                                .transpose().reset_index() \\\n",
    "                                .rename(columns={\"index\":f\"words_{i}\", 0:f\"importance_{i}\"})\n",
    "                importances.insert(0, \"score\", score)\n",
    "                importances.insert(0, \"key_point\", key_point)\n",
    "                df = pd.concat((df, importances), axis=1)\n",
    "            df.insert(0, 'argument', argument)\n",
    "            loo.append(df)\n",
    "    save_with_pickle(\"./Data/LOO_Data/leave_one_out.pkl\", loo)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Now we load or compute the mapping from the argument to all its dropped combinations\n",
    "data_path = \"./Data/LOO_Data/leave_one_out.pkl\"\n",
    "try:\n",
    "    leave_one_out = load_from_pickle(data_path)\n",
    "except:\n",
    "    leave_one_out = create_leave_one_out_for_args(topics, arguments)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's inspect the final result."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            argument  \\\n0  having a school uniform can reduce bullying as...   \n1  having a school uniform can reduce bullying as...   \n2  having a school uniform can reduce bullying as...   \n3  having a school uniform can reduce bullying as...   \n4  having a school uniform can reduce bullying as...   \n5  having a school uniform can reduce bullying as...   \n6  having a school uniform can reduce bullying as...   \n7  having a school uniform can reduce bullying as...   \n8  having a school uniform can reduce bullying as...   \n9  having a school uniform can reduce bullying as...   \n\n                                           key_point    score   words_0  \\\n0  School uniforms increase conformity or harm in...  0.74542    school   \n1  School uniforms increase conformity or harm in...  0.74542   uniform   \n2  School uniforms increase conformity or harm in...  0.74542    reduce   \n3  School uniforms increase conformity or harm in...  0.74542  bullying   \n4  School uniforms increase conformity or harm in...  0.74542  students   \n5  School uniforms increase conformity or harm in...  0.74542     style   \n6  School uniforms increase conformity or harm in...  0.74542    afford   \n7  School uniforms increase conformity or harm in...  0.74542    latest   \n8  School uniforms increase conformity or harm in...  0.74542    trends   \n9  School uniforms increase conformity or harm in...  0.74542     stand   \n\n   importance_0                                          key_point     score  \\\n0      0.105151  School uniform is harming the student's self e...  0.719613   \n1      0.120174  School uniform is harming the student's self e...  0.719613   \n2      0.148124  School uniform is harming the student's self e...  0.719613   \n3      0.152059  School uniform is harming the student's self e...  0.719613   \n4      0.122150  School uniform is harming the student's self e...  0.719613   \n5      0.200251  School uniform is harming the student's self e...  0.719613   \n6      0.023918  School uniform is harming the student's self e...  0.719613   \n7      0.115572  School uniform is harming the student's self e...  0.719613   \n8      0.085532  School uniform is harming the student's self e...  0.719613   \n9      0.159164  School uniform is harming the student's self e...  0.719613   \n\n    words_1  importance_1                                       key_point  \\\n0    school      0.106442  School uniforms are often uncomfortable/sexist   \n1   uniform      0.113617  School uniforms are often uncomfortable/sexist   \n2    reduce      0.145250  School uniforms are often uncomfortable/sexist   \n3  bullying      0.151784  School uniforms are often uncomfortable/sexist   \n4  students      0.120078  School uniforms are often uncomfortable/sexist   \n5     style      0.201913  School uniforms are often uncomfortable/sexist   \n6    afford      0.032066  School uniforms are often uncomfortable/sexist   \n7    latest      0.113921  School uniforms are often uncomfortable/sexist   \n8    trends      0.078351  School uniforms are often uncomfortable/sexist   \n9     stand      0.146390  School uniforms are often uncomfortable/sexist   \n\n   ...   words_2 importance_2                        key_point     score  \\\n0  ...    school     0.101659  School uniform reduces bullying  0.686188   \n1  ...   uniform     0.114814  School uniform reduces bullying  0.686188   \n2  ...    reduce     0.148596  School uniform reduces bullying  0.686188   \n3  ...  bullying     0.162226  School uniform reduces bullying  0.686188   \n4  ...  students     0.107013  School uniform reduces bullying  0.686188   \n5  ...     style     0.182905  School uniform reduces bullying  0.686188   \n6  ...    afford     0.051921  School uniform reduces bullying  0.686188   \n7  ...    latest     0.107768  School uniform reduces bullying  0.686188   \n8  ...    trends     0.082918  School uniform reduces bullying  0.686188   \n9  ...     stand     0.129567  School uniform reduces bullying  0.686188   \n\n    words_3 importance_3                                         key_point  \\\n0    school     0.111067  School uniforms create a sense of equality/unity   \n1   uniform     0.127685  School uniforms create a sense of equality/unity   \n2    reduce     0.204635  School uniforms create a sense of equality/unity   \n3  bullying     0.206463  School uniforms create a sense of equality/unity   \n4  students     0.124342  School uniforms create a sense of equality/unity   \n5     style     0.142583  School uniforms create a sense of equality/unity   \n6    afford     0.038486  School uniforms create a sense of equality/unity   \n7    latest     0.122354  School uniforms create a sense of equality/unity   \n8    trends     0.097824  School uniforms create a sense of equality/unity   \n9     stand     0.153177  School uniforms create a sense of equality/unity   \n\n      score   words_4 importance_4  \n0  0.673554    school     0.102590  \n1  0.673554   uniform     0.113907  \n2  0.673554    reduce     0.161033  \n3  0.673554  bullying     0.158163  \n4  0.673554  students     0.120000  \n5  0.673554     style     0.142879  \n6  0.673554    afford     0.028343  \n7  0.673554    latest     0.110510  \n8  0.673554    trends     0.080899  \n9  0.673554     stand     0.143127  \n\n[10 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>argument</th>\n      <th>key_point</th>\n      <th>score</th>\n      <th>words_0</th>\n      <th>importance_0</th>\n      <th>key_point</th>\n      <th>score</th>\n      <th>words_1</th>\n      <th>importance_1</th>\n      <th>key_point</th>\n      <th>...</th>\n      <th>words_2</th>\n      <th>importance_2</th>\n      <th>key_point</th>\n      <th>score</th>\n      <th>words_3</th>\n      <th>importance_3</th>\n      <th>key_point</th>\n      <th>score</th>\n      <th>words_4</th>\n      <th>importance_4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>school</td>\n      <td>0.105151</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>school</td>\n      <td>0.106442</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>school</td>\n      <td>0.101659</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>school</td>\n      <td>0.111067</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>school</td>\n      <td>0.102590</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>uniform</td>\n      <td>0.120174</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>uniform</td>\n      <td>0.113617</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>uniform</td>\n      <td>0.114814</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>uniform</td>\n      <td>0.127685</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>uniform</td>\n      <td>0.113907</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>reduce</td>\n      <td>0.148124</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>reduce</td>\n      <td>0.145250</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>reduce</td>\n      <td>0.148596</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>reduce</td>\n      <td>0.204635</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>reduce</td>\n      <td>0.161033</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>bullying</td>\n      <td>0.152059</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>bullying</td>\n      <td>0.151784</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>bullying</td>\n      <td>0.162226</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>bullying</td>\n      <td>0.206463</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>bullying</td>\n      <td>0.158163</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>students</td>\n      <td>0.122150</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>students</td>\n      <td>0.120078</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>students</td>\n      <td>0.107013</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>students</td>\n      <td>0.124342</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>students</td>\n      <td>0.120000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>style</td>\n      <td>0.200251</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>style</td>\n      <td>0.201913</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>style</td>\n      <td>0.182905</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>style</td>\n      <td>0.142583</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>style</td>\n      <td>0.142879</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>afford</td>\n      <td>0.023918</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>afford</td>\n      <td>0.032066</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>afford</td>\n      <td>0.051921</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>afford</td>\n      <td>0.038486</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>afford</td>\n      <td>0.028343</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>latest</td>\n      <td>0.115572</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>latest</td>\n      <td>0.113921</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>latest</td>\n      <td>0.107768</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>latest</td>\n      <td>0.122354</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>latest</td>\n      <td>0.110510</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>trends</td>\n      <td>0.085532</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>trends</td>\n      <td>0.078351</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>trends</td>\n      <td>0.082918</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>trends</td>\n      <td>0.097824</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>trends</td>\n      <td>0.080899</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>having a school uniform can reduce bullying as...</td>\n      <td>School uniforms increase conformity or harm in...</td>\n      <td>0.74542</td>\n      <td>stand</td>\n      <td>0.159164</td>\n      <td>School uniform is harming the student's self e...</td>\n      <td>0.719613</td>\n      <td>stand</td>\n      <td>0.146390</td>\n      <td>School uniforms are often uncomfortable/sexist</td>\n      <td>...</td>\n      <td>stand</td>\n      <td>0.129567</td>\n      <td>School uniform reduces bullying</td>\n      <td>0.686188</td>\n      <td>stand</td>\n      <td>0.153177</td>\n      <td>School uniforms create a sense of equality/unity</td>\n      <td>0.673554</td>\n      <td>stand</td>\n      <td>0.143127</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows  21 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leave_one_out[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Auxilliary experiment\n",
    "\n",
    "The idea for this experiment was to reverse the previous approach. Instead of compututing for each argument the respective argmax key-point we ask \"For each key-point, arguments were mapped to it?\". This allows to investigate which words were most prevalent for a specific key-point to be matched to an argument."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def create_kp_to_its_args():\n",
    "    argmax_kps = word_importances[word_importances.groupby(['topic',\"argument\"])['score'].transform(max) == word_importances['score']]\n",
    "    saved_word_rankings = {}\n",
    "    for key_point in key_points:\n",
    "        current_kp = argmax_kps.loc[argmax_kps[\"key_point\"]==key_point]\n",
    "        counter = defaultdict(int)\n",
    "        for mapping in current_kp[\"important_words\"]:\n",
    "            top_5 = {k:v for i, (k,v) in\n",
    "                     enumerate(sorted(mapping.items(), key=lambda x: x[1], reverse=True))\n",
    "                     if i <= 5}\n",
    "            for word in top_5.keys():\n",
    "                counter[word] += 1\n",
    "        counter = {k:v for i,(k,v) in enumerate(sorted(counter.items(), key=lambda x: x[1], reverse=True)) if i <= 10}\n",
    "        saved_word_rankings[key_point] = counter\n",
    "    return saved_word_rankings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "kptia = create_kp_to_its_args()\n",
    "for kp, important_words in kptia.items():\n",
    "    s = f\"{kp}\\n\"\n",
    "    for word, occurence in important_words.items():\n",
    "        s += f\"{word}\\t{occurence}\\n\"\n",
    "    s += \"\\n\"\n",
    "    with open(\"kps_importances.txt\", \"a\") as f:\n",
    "        f.write(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Helper functions for visualization / printing stuff\n",
    "\n",
    "# def get_stuff(l):\n",
    "#     new_df = pd.DataFrame()\n",
    "#     argument = l.iloc[:,0][0]\n",
    "#     scores = pd.concat([(l.iloc[:,(4*i)]) for i in range(1,6)], axis=1)\n",
    "#     words = l.iloc[:,3]\n",
    "#     df = pd.concat((words,scores),axis=1)\n",
    "#     kps = [x[1] for x in [l.iloc[:,(4*i-3)] for i in range(1,6)]]\n",
    "#     df = df.rename(columns={f\"importance_{i}\":kps[i] for i in range(len(kps))})\n",
    "#     df = df.rename(columns={\"words_0\":\"words\"})\n",
    "#     topic = list(predictions.loc[predictions[\"key_point\"]==kps[0]][\"topic\"])[0]\n",
    "#     reference_scores = [x[1] for x in [l.iloc[:,(4*i-2)] for i in range(1,6)]]\n",
    "#     return topic, argument, df, reference_scores\n",
    "\n",
    "# for i in tqdm_notebook(range(len(loo))):\n",
    "#     topic, argument, df, reference_scores = get_stuff(loo[i])\n",
    "#     name_excel = f\"./Results/LOO/sheet_{i}.xlsx\"\n",
    "#     name_metad = f\"./Results/LOO/sheet_{i}.txt\"\n",
    "#     if i in [0, 1283, 1690, 3306]:\n",
    "#         print(reference_scores)\n",
    "    # df.to_excel(name_excel)\n",
    "    # with open(name_metad, \"w\") as f:\n",
    "    #     f.write(f\"Topic: {topic}\\nArgument: {argument}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}